// AI æœåŠ¡ - ç»“æ„åŒ–æ”¶æ®æ•°æ®
import { AI_BASE_URL, AI_API_KEY, LLM_MODEL } from './config.js';

/**
 * è°ƒç”¨ LLM åˆ†æ OCR æ–‡æœ¬ï¼Œæå–ç»“æ„åŒ–æ”¶æ®æ•°æ®
 * @param {string} ocrText - OCR è¯†åˆ«åˆ°çš„åŸå§‹æ–‡æœ¬
 * @returns {Promise<Object>} åˆ†æç»“æœå’Œ Token ä½¿ç”¨æƒ…å†µ
 */
export async function callLLMToAnalyze(ocrText) {
  if (!AI_BASE_URL || !AI_API_KEY) {
    throw new Error('AI API not configured');
  }

  // 1. è·å–å½“å‰æ—¥æœŸ (ç”¨äºè¾…åŠ© AI åˆ¤æ–­å¹´ä»½å’Œæ ¡éªŒæ—¥æœŸåˆç†æ€§)
  const today = new Date().toISOString().split('T')[0]; // e.g., "2026-01-27"

  // 2. è®¾è®¡å¸¦æœ‰æ˜¾å¼æ¨ç†æ­¥éª¤çš„ Promptï¼ˆåŒ…å«ä¸¥æ ¼çš„è¾“å‡ºæ ¼å¼è¦æ±‚ï¼‰
  const systemPrompt = `
You are an expert OCR Data Extraction Auditor. Your goal is to extract precise structured data from receipts/invoices.

**Current Server Date:** ${today} (YYYY-MM-DD)
*Use this date to infer the year if missing, or to validate that the transaction date is not in the distant future.*

**CRITICAL: Your output format is STRICT. Follow these rules:**

1. **DO NOT include** any "Context Analysis", "Reasoning", "Step-by-step", or explanatory sections.
2. **ONLY output** the final result in the exact format below.
3. **NO introductory text** like "Here is the analysis" or "Based on the OCR".
4. **NO JSON output**.

**Analysis Rules (do this internally, but DO NOT write it in output):**
- **Region & Country**: Analyze currency symbols (Â¥=JP, $=US/SG/HK, â‚¬=EU), phone codes, language.
  - Japan (JP): Yen (Â¥), Japanese text, "+81"
  - China (CN): Simplified Chinese, "+86"
  - Korea (KR): Hangul, Won (â‚©), "+82"
  - Singapore (SG): SGD, English + Chinese
  
- **Date Format Rules** (critical - do this in your head only):
  - **Japan/China/Korea**: YY/MM/DD = 20YY-MM-DD (Big-Endian)
    - Example: "26/01/22" in Japan = 2026-01-22
  - **Singapore/UK/HK**: DD/MM/YY = 20YY-MM-DD (Little-Endian)
    - Example: "26/01/22" in UK = 2022-01-26
  - **USA**: MM/DD/YY = 20YY-MM-DD (Middle-Endian)

- **Store Name**: The most prominent header text
- **Items**: List key purchases with prices
- **Total**: Final amount with 3-letter currency code (JPY, SGD, USD, CNY, etc.)

**OUTPUT FORMAT (exactly this, nothing else):**

ğŸ¤– AI is structuring the data...

*Receipt Summary*
*Store*: [Store Name]
*Country*: [XX]
*Date*: [YYYY-MM-DD]
-------------------
[Item 1]   [Price 1]
[Item 2]   [Price 2]
-------------------
*Total*: [CURRENCY] [AMOUNT]
`;

  try {
    const res = await fetch(`${AI_BASE_URL}/chat/completions`, {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${AI_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        stream: false,
        model: LLM_MODEL,
        messages: [
          { role: 'system', content: systemPrompt },
          { 
            role: 'user', 
            content: `Extract data from this receipt OCR text:\n\n${ocrText}` 
          },
        ],
        temperature: 0.1, 
      }),
    });

    const data = await res.json();
    
    if (data.error) {
      console.error('LLM API Error Details:', data.error);
      throw new Error(data.error.message || 'LLM API returned an error');
    }

    const content = data.choices?.[0]?.message?.content;
    const usage = data.usage;

    // æ¸…ç† AI è¾“å‡ºï¼šç§»é™¤ Context Analysis ç­‰ä¸éœ€è¦çš„éƒ¨åˆ†
    const cleanedContent = cleanAIOutput(content || 'âš ï¸ AI could not analyze the text.');

    return { 
      text: cleanedContent, 
      usage: usage 
    };
  } catch (error) {
    console.error('Call LLM Failed:', error);
    throw error;
  }
}

/**
 * æ¸…ç† AI è¾“å‡ºï¼Œç§»é™¤ Context Analysis ç­‰å¤šä½™å†…å®¹
 * @param {string} text - AI åŸå§‹è¾“å‡º
 * @returns {string} æ¸…ç†åçš„æ–‡æœ¬
 */
function cleanAIOutput(text) {
  if (!text) return '';
  
  // æŸ¥æ‰¾ "Context Analysis:" æˆ–ç±»ä¼¼æ ‡è®°ï¼Œç§»é™¤ä¹‹åçš„å†…å®¹ï¼ˆå¦‚æœå®ƒåœ¨ Receipt Summary ä¹‹åï¼‰
  const summaryIndex = text.indexOf('*Receipt Summary*');
  if (summaryIndex > 0) {
    // åªä¿ç•™ Receipt Summary åŠä¹‹å‰çš„å†…å®¹ï¼ˆå»æ‰å‰é¢çš„åˆ†æï¼‰
    text = text.substring(summaryIndex);
  }
  
  // ç§»é™¤ Context Analysis éƒ¨åˆ†
  const patternsToRemove = [
    /\*\*Context Analysis:?\*\*?[\s\S]*$/i,  // ç§»é™¤ Context Analysis åŠä¹‹åæ‰€æœ‰å†…å®¹
    /Context Analysis:?[\s\S]*$/i,           // åŒä¸Šï¼Œä¸å¸¦æ˜Ÿå·
    /\*\*Step \d+:.*?\*\*[\s\S]*/i,          // ç§»é™¤ Step X åŠä¹‹å
    /Step \d+:.*?Analysis[\s\S]*/i,          // ç§»é™¤ Step X Analysis
    /\*\*Reasoning:?\*\*?[\s\S]*$/i,         // ç§»é™¤ Reasoning
    /Reasoning:?[\s\S]*$/i,                 // åŒä¸Š
  ];
  
  for (const pattern of patternsToRemove) {
    text = text.replace(pattern, '');
  }
  
  // æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
  text = text.replace(/\n{3,}/g, '\n\n').trim();
  
  return text;
}

/**
 * æ ¼å¼åŒ– Token ç»Ÿè®¡ä¿¡æ¯ï¼ˆä½¿ç”¨ MarkdownV2 å…¼å®¹æ ¼å¼ï¼‰
 * @param {Object} usage - Token ä½¿ç”¨æƒ…å†µ
 * @returns {string} æ ¼å¼åŒ–åçš„ç»Ÿè®¡æ–‡æœ¬
 */
export function formatTokenStats(usage) {
  if (!usage) return '';
  
  const inputTokens = usage.prompt_tokens || usage.input_tokens || 0;
  const outputTokens = usage.completion_tokens || usage.output_tokens || 0;
  
  // DeepSeek-V3.2 / V3 ä»·æ ¼
  // Input: $0.28 / 1M, Output: $0.42 / 1M
  const inputCost = (inputTokens / 1_000_000) * 0.28;
  const outputCost = (outputTokens / 1_000_000) * 0.42;
  const totalCost = inputCost + outputCost;
  
  // ä½¿ç”¨ç®€å•çš„ Markdownï¼Œé¿å…ç‰¹æ®Šå­—ç¬¦é—®é¢˜
  return `ğŸ“Š Token Usage & Cost
Input: ${inputTokens} | Output: ${outputTokens}
ğŸ’° Cost: $${totalCost.toFixed(6)}`;
}
